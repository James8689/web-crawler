# OpenAI API Key for content processing (if using OpenAI embeddings)
OPENAI_API_KEY=your_openai_api_key_here

# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here  # e.g., us-east-1-aws
PINECONE_INDEX_NAME=your_index_name_here
PINECONE_HOST=your_index_host_url_here  # e.g., my-index-12345.svc.us-east-1-aws.pinecone.io

# Customer Configuration
CUSTOMER_ID=your_customer_id_here  # Used to create dedicated namespace: web_crawl_{CUSTOMER_ID}

# Crawler Configuration (Optional)
# CHUNK_SIZE=500  # Size of text chunks for vector storage
# CHUNK_OVERLAP=50  # Overlap between chunks to maintain context
# EMBEDDING_MODEL=llama-text-embed-v2  # Model to use for text embeddings

# Directory Configuration (Optional)
# OUTPUT_DIR=processed_content  # Where processed content is stored
# CRAWLER_OUTPUT_DIR=crawler/winery_content  # Where crawler output is stored

# Vector Database Configuration (Optional)
# VECTOR_DIMENSION=1024  # Dimension of vectors in your Pinecone index
# NAMESPACE_PREFIX=web_crawl_  # Prefix for customer namespaces