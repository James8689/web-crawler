# E-commerce website configuration example

# Crawling parameters
start_urls:
  - "https://example-shop.com/products"
  - "https://example-shop.com/faqs"
  - "https://example-shop.com/returns"
max_depth: 2
include_external: false
batch_size: 15

# Content filtering
exclude_external_links: true
exclude_social_media_links: true
exclude_external_images: true
excluded_tags:
  - "footer"
  - "nav"
  - "header"
  - "aside"
  - "banner"

# LLM settings
llm_provider: "openai/gpt-4o-mini"
llm_instruction: |
  You are an assistant who extracts valuable content from e-commerce websites.
  Your task is to extract ONLY content that would be useful for customers looking for 
  information about products, shipping, returns, and company policies.
  
  Keep content about:
  - Product descriptions, specifications, and features
  - Pricing information and discounts
  - Shipping policies and timeframes
  - Return policies and warranties
  - Customer service information
  - FAQs about products and services
  
  FORMAT REQUIREMENTS:
  - Use clear headers for categories and subcategories
  - Preserve tables, lists, and structured information
  - Keep exact pricing and policy information
  
  Exclude:
  - Navigation elements and menus
  - Footers and headers
  - Social media links
  - User reviews (unless specifically analyzing product quality)

# Chunking parameters
chunk_size: 400  # Smaller chunks for more precise retrieval
chunk_overlap_ratio: 0.15

# Summarization
summary_model_name: "gpt-4o-mini"
summary_temperature: 0.2  # Lower temperature for more consistent results
summary_max_tokens: 600
summary_max_workers: 8

# Vector DB parameters
chunk_id_prefix: "ecommerce_shop"
record_retention_hours: 48
delete_old_records: true

# Output
output_dir: "ecommerce_content"
dry_run: false  # Upload to vectordb
verbose: true   # Show more detailed logs 